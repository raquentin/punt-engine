{"index":{"title":"Welcome","links":["notes/the-punt-engine-system"],"tags":[],"content":"This site hosts documentation on punt-engine, a high-frequency trading engine build for FPGAs and maintained by Trading @ Georgia Tech.\nObjective\nThis project is maintained by undergraduates. We use a $200 FPGA and have no bankroll. The main goal here is to build some of the first well-documented open source software in this genre.\nOverview\nSee The Punt Engine system.\nContributing\nAll contributors are welcome. Begin by reading some of this site and looking through open issues tagged “help wanted”.\nMany modules within our monorepo have dedicated pages here listing dependencies and local dev instructions, find them using the search bar.\nThere will inevitably be holes in the docs. If you have questions or want guidance, we hold office hours in our Discord.\nYou can direct other questions to race@raquent.in."},"notes/contributing-to-the-docs-site":{"title":"Contributing to the docs site","links":[],"tags":[],"content":"This is a walkthrough on how to clone this site, write a note, run the site on local, and update remote.\nDependencies\n\nnode v20\nnpm v9.3.1\ngit\na GitHub account\n\nNewer versions will likely work.\nCloning and running the site\npunt-engine is a monorepo, the docsite sits in a folder with all other modules in the engine.\nClone the entire thing and enter the docs folder:\ngit clone github.com/raquentin/punt-engine.git \\\ncd punt-engine/docs\nIn this folder, you’ll need to use node to install dependencies and run the build script:\nnpm i \\\nnpx quartz build --serve\nYou should have output in console directing you to http://localhost:8080. Open it in a browser and you’ll see the /docs site running locally.\nWriting a note\nBefore editing the repo, make a new branch:\ngit checkout -b &lt;branch-name&gt;\nIf you’re updating the docs to reflect changes in a new pr, just do this in the branch you’re already in.\nNavigate to punt-engine/docs/content/notes. You’ll see many notes, including this one. Touch a new one with a descriptive file name, perhaps the same as the title. This file name is that same path that will be in the URL.\nWith this file touched, you can go back to the browser and open it up, you’ll see a blank page to build on.\nHeader\nEach note needs a header defining its formatted title and date. The header for this note is:\n---\ntitle: Local Docsite Development\ndate: 10-15-2024\n---\nWrite yours similarly.\nBody Features\nI’ll quickly show some features you can do in these markdown files.\nLaTeX\nYou can write latex:\n$a - b &lt; b[a/b] &lt;= a$\nbecomes\na - b &lt; b[a/b] &lt;= a\nCode\nYou can write code:\n    ```haskell\n    topEntity :: Clock System -&gt; Reset System -&gt; Enable System -&gt; Signal System (Int, Int) -&gt; Signal System Int\n    topEntity = exposeClockResetEnable accumulatorMealy\n    ```\nbecomes\ntopEntity :: Clock System -&gt; Reset System -&gt; Enable System -&gt; Signal System (Int, Int) -&gt; Signal System Int\ntopEntity = exposeClockResetEnable accumulatorMealy\nMarkdown\nThese files are written in markdown, which has many formatting features. See this markdown cheat sheet.\nYou can also inspect the source of other notes and see how they’re constructed in the browser.\nUpdating remote\nWith your note finished on local, git push it, make a pr, and it will be reviewed. This site will update when it’s merged."},"notes/index":{"title":"Notes","links":[],"tags":[],"content":""},"notes/the-architecture-of-a-pipelined-order-book":{"title":"The architecture of a pipelined order book","links":["notes/moving-average-accumulator"],"tags":[],"content":"This page explains the design of a pipelined order book called Pipebomb. Pipebomb Is a Pipelined and Eventually Balanced Order-Managing Book. In short, the hardware module takes in a stream from Nasdaq’s ITCH protocol and maintains calculations of metrics that drive strategic decisions. These metrics are accumulated in discrete and configurable circuits that read from caches for internal order book data structures (see Caching). The following sections break down Pipebomb into it’s data structures, algorithms, and pipeline stages. Find more information in the Discord or the source.\nI/O\nLet’s talk concretely about the input and output of this entire circuit, first by comparing Pipebomb to a normal CPU.\nThe data models are entirely different. Where traditional von Neumann architectures are fetching instructions from memory, loading them into L1i, and jumping a PC throughout a process, Pipebomb’s instructions are a bit more transitive. The ITCH stream comes in on a wire, and we read this wire to perform the operation (something like ADD_ORDER, EXEC_ORDER, DEL_ORDER). Once the ITCH message’s operation has been performed, it’s useless.\nAnother key difference is that Pipebomb is not Turing-complete. Traditional processors provide an effectively Turing-complete ISA which can perform any computation given time and resources. Write your program, compile it for your architecture, and run it. The whole appeal of using the FPGA platform is that we aren’t bound by this. For a quick example, imagine compiling some pattern-matching logic with 100 patterns to assembly. Ignoring the jump table optimization for a minute, your assembly will have hundreds of instructions comparing the value to each branch and jumping to the relevant label if it is. This will take many clock cycles. In contrast, on an FPGA we could just synthesize this logic with a multiplexer. It’s a function of combinational logic and will take a fraction of a single clock cycle.\nITCH messages as CPU instructions\nSo without some traditional ISA, what do we have? We have a stream of ITCH messages that we interpret as CPU instructions. They look something like this:\ntypedef enum logic [3:0] {\n  ITCH_ADD              = 4&#039;h1,\n  ITCH_OEXEC            = 4&#039;h2,\n  ITCH_PEXEC            = 4&#039;h3,\n  ITCH_CANCEL           = 4&#039;h4,\n  ITCH_DELETE           = 4&#039;h5,\n  ITCH_REPLACE          = 4&#039;h6,\n} opcode_t;\n \ntypedef enum logic {\n  SIDE_BID = 1&#039;b0,\n  SIDE_ASK = 1&#039;b1\n} side_t;\n \ntypedef struct packed {\n  opcode_t          opcode;\n  logic             valid;\n  logic [63:0]      timestamp;\n  side_t            side;\n  logic [ORDER_ID_BITS-1:0] order_id;\n  logic [PRICE_BITS-1:0]    price;\n  logic [QUANTITY_BITS-1:0] quantity;\n  logic [ORDER_ID_BITS-1:0] new_order_id; // replace only\n} inst_t;\nInstead of opcodes like add or lw, we have those from the ITCH protocol description.\nAccumulators\nAccumulators are the outputs. The whole point of writing an order book here is to quickly find market indicators that drive strategic decisions. These indiators are things like moving average, volatility, and mid-price.\nState\nBetween this input stream and these accumulators is a lot of state:\n\nThe depth of each price in the market. The market is split up into two arrays mapping price levels to quantities, one for bids and one for asks.\nAn index of previous orders. The ITCH_ADD instruction supplies an orderID, a price, and a quantity. The ITCH_DELETE instruction only supplies and orderID. We need to save the price and quantity associated with each orderID so when the order’s state changes at Nasdaq we can update our underlying data structures accordingly despite not immediately knowing what price level the order was.\nCaches. Some architectural decisions mean that some order book traversal algorithms have poor time complexities. We fix this by caching things relevant to them.\nMessages. We queue messages in a FIFO to ensure we don’t double count nor lose any instructions.\n\nPipelining\n\nHere’s the order book broken down into its modules and their dependencies. For a quick summary, orders come in, are decoded into into inst_t, and placed in a queue. Every cycle, we dequeue an instruction (perhaps multiple later on). If this instruction is not an ITCH_ADD, that implies the order it’s updating already exists, so we need to fetch information about it from the Order Map. With all info in hand, we split off into the Bid side and the Ask side. Now we’re parallelized on two axes, performing order book update operations on disjoint data structures. Then we have the accumulators, which maintain the inputs to strategic decisions as described above.\nMessage decoder and FIFO\nAs mentioned, the “instructions” in our architecture are not compiled binaries that carry out some process loaded into memory. They are a stream of ITCH messages. This stream is raw bytes on a wire, we’ll need to parse them into a sort of instruction.\nThe implementation of this parser is complex. Punt Engine’s design is not yet defined. Regardless, messages will be parsed into an inst_t and enqueued into the Message FIFO. From there the rest of the pipeline will dequeue instructions and execute them.\nWith this setup, we won’t execute the same instruction twice as it’s dequeued and deleted after is passed through the pipeline.\nThere are a few techniques to not miss instructions, which involves overflowing of the FIFO:\n\nsend backpressure signal to exchange\nlower in the network stack, drop irrelevant ethernet frames or other structures\nhave multiple entire pipelines processing orders. We are working to find parallelism on this axis.\n\nRouter and order map\nAt this point, we have a single inst_t and we’re ready to begin updating our order book. Recall what inst_t looks like:\ntypedef struct packed {\n  opcode_t          opcode;\n  logic             valid;\n  logic [63:0]      timestamp;\n  side_t            side;\n  logic [ORDER_ID_BITS-1:0] order_id;\n  logic [PRICE_BITS-1:0]    price;\n  logic [QUANTITY_BITS-1:0] quantity;\n  logic [ORDER_ID_BITS-1:0] new_order_id; // replace only\n} inst_t;\nKnow that no instruction uses each of these signals itself. The structure is essentially a union of all the data that any one instruction needs. We wrap them into inst_t and then split the bus carrying the instruction to get the data we actually want.\nHere’s a quick breakdown of inst_t:\n\nopcode is the type of ITCH message (ADD/EXEC/DELETE).\nvalid marks whether the message contains meaningful data and facilitates bubbling and error handling.\ntimestamp is the timestamp of the request. Perhaps it can be useful for synchronization if we parallelize the design later.\nside is either bid or ask. We’ll route the instruction to the relevant side processor based on this.\nprice is a price. Note that we can perform some type of bucketing with the price to decrease the perceived book sparsity. If it doesn’t impact our strategy too much, dividing price by 0.04 or 0.08 will use less energy, less surface area, and increase book density. Many of the design decisions in later stages are particularly efficient for dense books. Dense books have relatively small gaps between populated price levels. It’s a bit beyond the scope of this post, but previous designs considered using a self-balancing tree backing structure to be more efficient for sparse books1. That’s where the “Eventually Balanced” in the Pipebomb acronym comes from.\nquantity is the additional depth to be added at the relevant price level by this order. In the case of CANCEL or DELETE instructions, this quantity will be negative and pulled from the Order Map, see below.\nnew_order_id is only for REPLACE instructions.\n\nThe goal of this part of the order book is to take instructions and update the order books state based on them. As hinted at earlier, the effect of DELTE and CANCEL operations is not explicit from the ITCH messages they’re parsed from. You can imagine that deleting an order involves removing the depth that it added to its price level in the order book. We’d do this by decrementing the depth there by the amount that was initially added. The problem is that the DELETE instruction only specifies the order_id to be deleted, it doesn’t include the price or quantity to be decremented. For that reason we have an Order Map, a mapping of order_ids to prices and quantitys. This pipeline stage fetches data from this map when necessary and prepares it for the next stage, which actually acts out the message’s effect on the book.\nBid and ask processors\nThe bid and the ask processor are degeneralizations of the side processor, another stage in this pipeline. Each processor is a manager for two underlying data structures.\nThe first is a circular buffer. It’s an array with a predefinized length, let’s call that m. Ignoring bucketing for a second, imagine we’re trading BTC. Then buffer[$100,000.01] = the total volume across all orders at the same price level as $100,000.01 in this side of the book. If we’re counting from $0.00 though, this array is going to be huge. Say we offset it a bit, starting at $90,000.00, so buffer[$100,000.01 - $90,000.00] = the total volume across all orders at the same price level as $100,000.01. With this we save space, but certainly if BTC increases to $1m, we can’t accomodate. So the final design involves taking the price index mod m and getting that index of the buffer. Here buffer[$100,000.01 mod 10.24] is the total volume. Obviously, if we index $100,010.25, we will get the same quantity as we did for $100,000.01. Making this space optimization assumes that the strategy that we’re working with only really cares about the inside of the book. Good order book implementations are driven by good strategies, finding a strategy that is profitable for a small m will improve this part of the pipeline.\nThe second is a k-best price levels cache. Recall the tradeoff between the circular buffer design and the self-balancing tree design mentioned above. The circular buffer has O(1) random access time, but is very space inefficient for sparse books. With sparse books our backing array will be full of zeroes, with only a small percentage of indices actually populated with orders. The self-balancing tree avoids this by only managing nodes for price levels that are populated, with O(log(n)) random access time. Another skip-list like optimization on top of that makes certain accumulator calculations faster. Each side of the book maintains the k best bids or asks for use in calculating accumulators.\nCaching common indicator parameters\nLet’s talk more on this k-best cache. A problem with the circular buffer design is that updating the best n bids or n asks takes linear time. You need to move from the middle of the book towards the poles until you find k populated price levels. Doing this on every clock cycle would make this the slowest stage in the pipeline, decreasing the global clock speed. Instead, we can just cache the k levels.\nLet’s look at some Verilog:\nmodule price_cache #(\n  parameter CACHE_LEVELS = 5  // k\n)(\n  // ... interface signals ...\n \n  // Input from side processor\n  input  logic [PRICE_BITS-1:0]  update_price,\n  input  logic [QUANTITY_BITS-1:0] update_quantity,\n  input  logic                   update_valid,\n  input  logic                   is_bid_side\n \n  // Output to metrics calculator\n  output price_level_t           cached_levels[CACHE_LEVELS],\n  output logic                   cache_valid\n);\nEach side processor has a price_cache between it and the metrics calculator. This cache is sorted.\nAlso note that the side processor can update the best price in O(1) time like this:\nPROCESS_ADD: begin\n    price_levels[process_idx].total_quantity &lt;= price_levels[process_idx].total_quantity + process_quantity;\n    price_levels[process_idx].valid &lt;= 1&#039;b1;\n \n    if (is_better_than_current_best(process_idx)) begin\n      update_best_needed &lt;= 1&#039;b1;\n    end\n  end\nBut it’s for k &gt; 1 where we have to traverse down the price levels.\nNow within the cache, there’s two main operations:\n\nSingle-level updating. If the update_price from the side processor is already in the cache, we just update it by update_quantity. If update_quantity is 0 though, we need to remove it. We’d shift all the entries in the cache up in the buffer, then clear the last entry. If the update_price is not in the cache, we add this new level in, shifting all current cache entries down.\nCache rebalancing. Recall how the side processors are backed by circular buffers. When the best price crosses some multiple of m, the indices of the buffer now have a new meaning, and the indices in the cache are useless. We’d need to rebuild the entire cache.\n\nAccumulators\nAccumulators are the thing that all other levels have worked to produce. We’ve defined them above, let’s just see what they look like.\nYou can calculate the mid-price based on the bid and ask caches:\nalways_comb begin\n  if (bid_cached_levels[0].valid &amp;&amp; ask_cached_levels[0].valid) begin\n    mid_price = (bid_cached_levels[0].price + ask_cached_levels[0].price) &gt;&gt; 1;\n    mid_price_valid = 1&#039;b1;\n  end else begin\n    mid_price = last_mid_price;\n    mid_price_valid = 1&#039;b0;\n  end\nend\nYou can calculate exponential moving averages similarly:\nalways_ff @(posedge clk) begin\n  if (update_metrics &amp;&amp; mid_price_valid) begin\n    // EMA = α * price + (1-α) * previous_EMA\n    ema_short_reg &lt;= fixed_multiply(mid_price, ALPHA_SHORT) + fixed_multiply(ema_short_reg, ONE - ALPHA_SHORT);\n \n    ema_medium_reg &lt;= fixed_multiply(mid_price, ALPHA_MEDIUM) + fixed_multiply(ema_medium_reg, ONE - ALPHA_MEDIUM);\n \n    ema_long_reg &lt;= fixed_multiply(mid_price, ALPHA_LONG) + fixed_multiply(ema_long_reg, ONE - ALPHA_LONG);\n  end\nend\nYou can imagine how other accumulators use the caches or even communicate directly with the side processors to grab inputs and maintain some market indicator.\nAll together\nWe’ve defined the I/O of this circuit, its pipeline stages, and the data structures and algorithms that make everything possible. Along with all of these pipeline stage modules, we’d have a top module that wraps all of them and provides an interface to the order book. We’d connect this to an ITCH parserthat itself handles the OSI stack and stream connection. We’d likely output to some DMA controller that would use AMD IP and Madlib to communicate across PCIe to a host OS.\nLook again at the order book broken down into its modules. Do you understand it? If not, send a message in Discord or come to office hours.\n\nFootnotes\n\n\nThis prior design was inspired by Exploring the Potential of Reconfigurable Platforms for Order Book Update. ↩\n\n\n"},"notes/the-intuition-behind-moving-avg-accumulator":{"title":"Building a moving average accumulator core","links":[],"tags":[],"content":"This post guides readers from a blank folder to a working and tested moving average accumulator gateware circuit. I’ll first describe the intuition for the algorithm, then implement it in SystemVerilog, then write a Verilator testbench in C++.\nExactly what we’re building is a clocked circuit that takes in a price and returns the average price over the last n samples. We’ll parameterize k and the bit width of the price, namely n, using the SystemVerilog parameter keyword.\nSetup\nThis post is a coding exercise. Create a new folder with nothing in it.\nYou’ll need these dependencies:\n\nVerilator\nA C++ compiler\nCMake\n\nOur project uses Nix for this. You’re recommended to use our  Nix Flake developer environment to get the exact versions our project builds with. You can delete all the Haskell/Clash stuff, we’re just working with Verilog today. Otherwise just download the deps yourself.\nCreate these files:\n\nMakefile: We’ll use CMake to control more complex Verilator and make commands.\nmov_avg_acc.sv: This is the moving average accumulator. We’ll implement it in SystemVerilog.\ntestbench.cpp: We compare the output of a software testbench to that of our accumulator core to ensure it workstestbench.cpp`:\n\nNow you’re setup. Let’s begin.\nIntuition\nConsider the simplest interface to an accumulator circuit. Like any clocked circuit, we’ll have an input wire clk. Likewise, we’ll have an input wire reset.\nThat’s the foundation, but what is the real i/o for this circuit? We take in a stream of prices. What we’re calling a price is a value represented by a bus of n wires. These wires together allow the representation of 2^n - 1 values. In our case, these values are prices. We’ll have an input wire unsigned d_in, which holds the price that we are to sample on the next rising clock edge. We don’t want to lock users of this circuit to only a certain n value; our core should be agnostic to the bit depth of the price of the asset that it is accumulating. So we’ll abstract away this n using a parameter called DataWidth.\nWith these inputs, we perform some logic, and produce an output. This output is going to a price, so it will be the same type as the d_in wire.\nHere’s what that looks like in mov_avg_acc.sv:\nmodule mov_avg_acc #(\n    parameter integer Exponent  /*verilator public*/  = 3,\n    parameter integer DataWidth  /*verilator public*/ = 16\n) (\n    input wire clk,\n    input wire reset,\n    input wire unsigned [DataWidth-1:0] d_in,\n    output reg unsigned [DataWidth-1:0] d_out\n);\nLet’s break down this syntax a bit:\n\nmodule mov_avg_acc defines a reusable hardware component called mov_avg_acc. Other modules can embed this module, linking their wires to the inputs and outputs of our core.\nNext is a list bound by #(...). This is the parameter list, here go constants like Exponent (log_2(k)) and DataWidth (n). When synthesizing our mov_avg_acc core, we can pass these parameters in without having to go in and change the internal RTL of our circuit.\nFinally is this list bound by (...). Within this list are all i/o. In our case, we have the three inputs and one output described above.\n\nCircular buffers\nLet’s ignore the interface described above and generalize the moving average problem a bit. We have a stream of prices over time, and want to maintain the average over the last k of them. Naively, computing an average involves summing up all samples in a set and dividing that sum by the size of the set.\nConsider an implementation of the circuit that maintains an stack-like array structure of infinite size. On each clock edge, we push the current price (the value of d_in) on top of this stack. Then we sum up the top k elements on the stack, divide that sum by k, and put that result into the register d_out.\nThe problem with this is that we don’t infinite memory. So instead of an infinitely large stack, we’ll maintain an array of size k, and a pointer to the oldest index in k, called oldest_index. Since we’re only concerned with the k most recent samples, on a given clock edge, the price in the array at oldest_index was k samples ago and hence does not impact the value we push to d_out. So on this new edge, we can just overwrite array[oldest_index] with d_in, fixing the infinite memory problem.\nSo now, we have an array in our circuit with the k most recent samples. On each cycle, we could sum up the array in O(k) time, then divide by k and be done. That’s a bit naive though, we can sum the array in O(1) time by realizing that on a given cycle, we increase the sum by d_in and decrease it by array[oldest_index], AKA the price k samples ago. So instead of summing up the whole array, we just subtract by the oldest sample and add the newest one: d_in. Then we divide by k.\nAn optimization for k = 2^n.\nThere’s one last optimization. Imagine that in the circuit above k is 10; we’re calculating the average over the last 10 samples. Dividing by 10 on computers is slow and difficult. We either use a floating point unit and deal with fractions of the price, or use fast division algorithms. Look up hardware division algorithms if you care to learn more, but the point here is that they are slow and we want to avoid them when possible.\nWhen k = 2^n (for some n \\in \\mathbb{R}, not the n from before related to bit depth), we can use the right shift operation to divide the sum by k in less than one clock cycle. Instead of performing some series of operations to implement a general division algorithm, we essentially just ignore the least significant k bits of the sum.\nImplementation\nYou’ve learned the algorithm. Let’s implement it. There’s a few things to note first before we get into the full code:\nThe bit width of the sum of array != n\nRecall that the array consists of k elements of size n ([DataWidth-1:0]). In the calculation of d_out, we can’t simply store this sum in an n-bit wire because we will have overflow. To prevent overflow, our temporary sum wire must be of size k+n. So in our circuit we have:\nreg unsigned [AccWidth-1:0] acc;\nNote that this is not a reg in the circuit’s i/o list; it’s a local/intermediate reg.\nlocalparam\nFor convenience, we have:\nlocalparam integer N = 1 &lt;&lt; Exponent;\nlocalparam integer AccWidth = DataWidth + Exponent;\nN defines the aforementioned n but uppercase to match formatting standards. AccWidth is the bit depth of the acc reg, which is the numerator in the average calculation, AKA the sum of the elements of array. It’s of depth k+n.\nThe localparam keybord is a bit like C’s #define. We setup these aliases to avoid pasting those rvalues all over the place.\nfor loops in hardware description languages\nIn the code below, you’ll see a loop that instantiates the elements of the array of sample history, here named sample_buffer:\nfor (i = 0; i &lt; N; i++) begin\n    sample_buffer[i] &lt;= &#039;0;\nend\nRemember that we’re describing hardware, not writing software. for here is not the imperative for loop that it is in software. Here, it essentially is a compile-time for that expands into an assignment of each element of the sample buffer to 0 without having to copy-paste that assignment for each hardcoded i upto N. This loop does NOT perform some type of iterative operation at runtime.\nSign extension\nRecall the operation where we subtract out the oldest sample and add in the newest. Here’s the code for that:\nacc &lt;= acc\n - {\n     {(AccWidth - DataWidth){sample_buffer[oldest_index][DataWidth-1]}},\n     sample_buffer[oldest_index]\n   }\n + {{(AccWidth - DataWidth){d_in[DataWidth-1]}}, d_in};\nIn short, we’re setting acc &lt;= acc - subtrahend + addend.\nIn the subtrahend, {(AccWidth - DataWidth){sample_buffer[oldest_index][DataWidth-1]}} performs a sign-extension. That’s a bit confusing though since all these values are unsigned. It’s really just a pattern to extend sample_buffer[oldest_index] to the size of the larger acc to allow them to be subtracted. It takes the most significant bit of the oldest sample and replicated it upto the size of acc, then concatenates that with the oldest sample itself.\nSimilarly, {{(AccWidth - DataWidth){d_in[DataWidth-1]}}, d_in} expands d_in to the width of acc.\nThe entire SystemVerilog core\nWith the intuition and notes out of the way, we’ve almost accidentally built the whole circuit. It’s pasted below with comments inline.\nmodule moving_average_accumulator #(\n    // we use Exponent to enforce that k = 2^n\n    parameter integer Exponent  /*verilator public*/  = 3,\n    parameter integer DataWidth  /*verilator public*/ = 16 // n\n) (\n    input wire clk,\n    input wire reset,\n    input wire unsigned [DataWidth-1:0] d_in,\n    output reg unsigned [DataWidth-1:0] d_out\n);\n \n  localparam integer K = 1 &lt;&lt; Exponent;\n  localparam integer AccWidth = DataWidth + Exponent;\n \n  // holds sum of last `N` samples\n  reg unsigned [AccWidth-1:0] acc;\n \n  // circular buffer storing last k samples\n  reg unsigned [DataWidth-1:0] sample_buffer[K];\n \n  // index of oldest element in `sample_buffer`\n  integer oldest_index;\n \n  // loop\n  integer i;\n \n  always_ff @(posedge clk or posedge reset) begin\n    if (reset) begin\n      acc   &lt;= &#039;0;\n      d_out &lt;= &#039;0;\n \n      // reset sample buffer\n      for (i = 0; i &lt; K; i++) begin\n        sample_buffer[i] &lt;= &#039;0;\n      end\n \n      oldest_index &lt;= 0;\n    end else begin\n      // subtract oldest, add newest\n      acc &lt;= acc\n       - {\n           {(AccWidth - DataWidth){sample_buffer[oldest_index][DataWidth-1]}},\n           sample_buffer[oldest_index]\n         }\n       + {{(AccWidth - DataWidth){d_in[DataWidth-1]}}, d_in};\n \n      // overwrite oldest sample\n      sample_buffer[oldest_index] &lt;= d_in;\n \n      // inc oldest_index. wrap around using modulo K\n      oldest_index &lt;= (oldest_index + 1) % K;\n \n      // compute moving average by dividing by 2^exponent\n      d_out &lt;= acc[AccWidth-1:Exponent];  // like a right shift\n    end\n  end\n \nendmodule\nTestbench\nWe have the gateware core completed; now let’s test it. If we can assume some knowledge of C++, I can just explain the testbench in comments:\n// verilator compiles our mov_avg_acc.sv to cpp, that&#039;s the file below\n#include &quot;Vmoving_average_accumulator.h&quot;\n// we&#039;ll instantiate it in our function, run some inputs through it, and compare\n \n#include &quot;verilated.h&quot;\n#include &quot;verilated_vcd_c.h&quot;\n#include &lt;cstdlib&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n \n#define SIM_TIME 20 // Simulation time in clock cycles\n \nint main(int argc, char **argv) {\n  // setup\n  Verilated::commandArgs(argc, argv);\n  // top is a C++ version of the SystemVerilog core we wrote\n  Vmoving_average_accumulator *top = new Vmoving_average_accumulator;\n  VerilatedVcdC *tfp = nullptr;\n  vluint64_t sim_time = 0;\n \n  // these are the input wires we had in out circuit.\n  // we&#039;re setting them up\n  // reset-&gt;1 sets up the sample_buffer\n  top-&gt;clk = 0;\n  top-&gt;reset = 1;\n  top-&gt;d_in = 0;\n \n  // what we&#039;re really doing from here down is setting up the &quot;expected&quot; values\n  // that we&#039;ll compare to the output of our verilog circuit.\n  // to get these expected values, we need to rewrite our circuit&#039;s logic in C++\n \n  // same constants from sv\n  const int Exponent = 3;\n  const int N = 1 &lt;&lt; Exponent;\n  const int DataWidth = 16;\n \n  // our C++ version doesn&#039;t naturally respond to the clock\n  // and hence doesn&#039;t have a delay in its output\n  // we store the values like this to mock this delay\n  uint16_t one_ago = 0;\n  uint16_t two_ago = 0;\n  uint16_t expected_out = 0;\n \n  std::vector&lt;uint16_t&gt; sample_buffer(N, 0);\n  uint32_t acc = 0; // using 32 bits to prevent overflow\n \n  // current index pointing to the oldest sample\n  int oldest_index = 0;\n \n  // simulation loop\n  while (sim_time &lt; SIM_TIME) {\n    // invert clock\n    top-&gt;clk = !top-&gt;clk;\n \n    // allow time for reset\n    if (sim_time &gt; 4)\n      top-&gt;reset = 0;\n \n    // the real logic for the rising edge of the clock\n    if (top-&gt;clk) {\n      // pseudorandom input price\n      uint16_t input_data = (3 * sim_time + 2) % 8031;\n      top-&gt;d_in = input_data; // assert d_in with that price\n \n      // remake the logic in C++\n      if (!top-&gt;reset) {\n        acc -= sample_buffer[oldest_index];\n        acc += input_data;\n        sample_buffer[oldest_index] = input_data;\n \n        oldest_index = (oldest_index + 1) % N;\n \n        // mock the delay\n        two_ago = one_ago;\n        one_ago = expected_out;\n        expected_out = acc &gt;&gt; Exponent;\n \n        // compare and err if bad\n        // if the sim ends without error, we passed\n        if (top-&gt;d_out != two_ago) {\n          std::cerr &lt;&lt; &quot;Mismatch on simtime&quot; &lt;&lt; sim_time &lt;&lt; &quot;: expected &quot;\n                    &lt;&lt; two_ago &lt;&lt; &quot;, got &quot; &lt;&lt; top-&gt;d_out &lt;&lt; std::endl;\n          return EXIT_FAILURE;\n        }\n      }\n    }\n \n    top-&gt;eval();\n \n \n    sim_time++;\n  }\n \n  top-&gt;final();\n \n  // cleanup\n  delete top;\n \n  // test passed\n  std::cout &lt;&lt; &quot;Simulation completed successfully.&quot; &lt;&lt; std::endl;\n  return EXIT_SUCCESS;\n}\nMakefile\nIn order to run this locally and in CI, we’ll use this Makefile:\n# Top-level module name\nTOP_MODULE = moving_average_accumulator\n \n# Verilog source files\nVERILOG_SOURCES = $(TOP_MODULE).sv\n \n# C++ testbench file\nTESTBENCH = tb.cpp\n \n# Output directory\nOBJ_DIR = obj_dir\n \n# Simulation executable\nSIM_EXE = $(OBJ_DIR)/V$(TOP_MODULE)\n \n# Default target\n.PHONY: all\nall: run_simulation\n \n# Compile Verilog and C++ sources\n$(SIM_EXE): $(VERILOG_SOURCES) $(TESTBENCH)\n\tverilator --cc $(VERILOG_SOURCES) --exe $(TESTBENCH) --trace\n\tmake -j -C $(OBJ_DIR) -f V$(TOP_MODULE).mk V$(TOP_MODULE)\n \n# Run the simulation\n.PHONY: run_simulation\nrun_simulation: $(SIM_EXE)\n\t./$(SIM_EXE)\n \n# Clean up generated files\n.PHONY: clean\nclean:\n\trm -rf $(OBJ_DIR) waveform.vcd\n \n# Phony target for CI testing (exits with non-zero status on failure)\n.PHONY: test\ntest: run_simulation\nRunning it\nThat’s all the code. Let’s run it. If you have the dependecies setup, run make test."},"notes/the-punt-engine-system":{"title":"The Punt Engine system","links":[],"tags":[],"content":""},"notes/moving-average-accumulator":{"title":"Building a moving average accumulator core","links":[],"tags":[],"content":"This post guides readers from a blank folder to a working and tested moving average accumulator gateware circuit. I’ll first describe the intuition for the algorithm, then implement it in SystemVerilog, then write a Verilator testbench in C++.\nExactly what we’re building is a clocked circuit that takes in a price and returns the average price over the last n samples. We’ll parameterize k and the bit width of the price, namely n, using the SystemVerilog parameter keyword.\nSetup\nThis post is a coding exercise. Create a new folder with nothing in it.\nYou’ll need these dependencies:\n\nVerilator\nA C++ compiler\nCMake\n\nOur project uses Nix for this. You’re recommended to use our  Nix Flake developer environment to get the exact versions our project builds with. You can delete all the Haskell/Clash stuff, we’re just working with Verilog today. Otherwise just download the deps yourself.\nCreate these files:\n\nMakefile: We’ll use CMake to control more complex Verilator and make commands.\nmov_avg_acc.sv: This is the moving average accumulator. We’ll implement it in SystemVerilog.\ntestbench.cpp: We compare the output of a software testbench to that of our accumulator core to ensure it workstestbench.cpp`:\n\nNow you’re setup. Let’s begin.\nIntuition\nConsider the simplest interface to an accumulator circuit. Like any clocked circuit, we’ll have an input wire clk. Likewise, we’ll have an input wire reset.\nThat’s the foundation, but what is the real i/o for this circuit? We take in a stream of prices. What we’re calling a price is a value represented by a bus of n wires. These wires together allow the representation of 2^n - 1 values. In our case, these values are prices. We’ll have an input wire unsigned d_in, which holds the price that we are to sample on the next rising clock edge. We don’t want to lock users of this circuit to only a certain n value; our core should be agnostic to the bit depth of the price of the asset that it is accumulating. So we’ll abstract away this n using a parameter called DataWidth.\nWith these inputs, we perform some logic, and produce an output. This output is going to a price, so it will be the same type as the d_in wire.\nHere’s what that looks like in mov_avg_acc.sv:\nmodule mov_avg_acc #(\n    parameter integer Exponent  /*verilator public*/  = 3,\n    parameter integer DataWidth  /*verilator public*/ = 16\n) (\n    input wire clk,\n    input wire reset,\n    input wire unsigned [DataWidth-1:0] d_in,\n    output reg unsigned [DataWidth-1:0] d_out\n);\nLet’s break down this syntax a bit:\n\nmodule mov_avg_acc defines a reusable hardware component called mov_avg_acc. Other modules can embed this module, linking their wires to the inputs and outputs of our core.\nNext is a list bound by #(...). This is the parameter list, here go constants like Exponent (log_2(k)) and DataWidth (n). When synthesizing our mov_avg_acc core, we can pass these parameters in without having to go in and change the internal RTL of our circuit.\nFinally is this list bound by (...). Within this list are all i/o. In our case, we have the three inputs and one output described above.\n\nCircular buffers\nLet’s ignore the interface described above and generalize the moving average problem a bit. We have a stream of prices over time, and want to maintain the average over the last k of them. Naively, computing an average involves summing up all samples in a set and dividing that sum by the size of the set.\nConsider an implementation of the circuit that maintains an stack-like array structure of infinite size. On each clock edge, we push the current price (the value of d_in) on top of this stack. Then we sum up the top k elements on the stack, divide that sum by k, and put that result into the register d_out.\nThe problem with this is that we don’t infinite memory. So instead of an infinitely large stack, we’ll maintain an array of size k, and a pointer to the oldest index in k, called oldest_index. Since we’re only concerned with the k most recent samples, on a given clock edge, the price in the array at oldest_index was k samples ago and hence does not impact the value we push to d_out. So on this new edge, we can just overwrite array[oldest_index] with d_in, fixing the infinite memory problem.\nSo now, we have an array in our circuit with the k most recent samples. On each cycle, we could sum up the array in O(k) time, then divide by k and be done. That’s a bit naive though, we can sum the array in O(1) time by realizing that on a given cycle, we increase the sum by d_in and decrease it by array[oldest_index], AKA the price k samples ago. So instead of summing up the whole array, we just subtract by the oldest sample and add the newest one: d_in. Then we divide by k.\nAn optimization for k = 2^n.\nThere’s one last optimization. Imagine that in the circuit above k is 10; we’re calculating the average over the last 10 samples. Dividing by 10 on computers is slow and difficult. We either use a floating point unit and deal with fractions of the price, or use fast division algorithms. Look up hardware division algorithms if you care to learn more, but the point here is that they are slow and we want to avoid them when possible.\nWhen k = 2^n (for some n \\in \\mathbb{R}, not the n from before related to bit depth), we can use the right shift operation to divide the sum by k in less than one clock cycle. Instead of performing some series of operations to implement a general division algorithm, we essentially just ignore the least significant k bits of the sum.\nImplementation\nYou’ve learned the algorithm. Let’s implement it. There’s a few things to note first before we get into the full code:\nThe bit width of the sum of array != n\nRecall that the array consists of k elements of size n ([DataWidth-1:0]). In the calculation of d_out, we can’t simply store this sum in an n-bit wire because we will have overflow. To prevent overflow, our temporary sum wire must be of size k+n. So in our circuit we have:\nreg unsigned [AccWidth-1:0] acc;\nNote that this is not a reg in the circuit’s i/o list; it’s a local/intermediate reg.\nlocalparam\nFor convenience, we have:\nlocalparam integer N = 1 &lt;&lt; Exponent;\nlocalparam integer AccWidth = DataWidth + Exponent;\nN defines the aforementioned n but uppercase to match formatting standards. AccWidth is the bit depth of the acc reg, which is the numerator in the average calculation, AKA the sum of the elements of array. It’s of depth k+n.\nThe localparam keybord is a bit like C’s #define. We setup these aliases to avoid pasting those rvalues all over the place.\nfor loops in hardware description languages\nIn the code below, you’ll see a loop that instantiates the elements of the array of sample history, here named sample_buffer:\nfor (i = 0; i &lt; N; i++) begin\n    sample_buffer[i] &lt;= &#039;0;\nend\nRemember that we’re describing hardware, not writing software. for here is not the imperative for loop that it is in software. Here, it essentially is a compile-time for that expands into an assignment of each element of the sample buffer to 0 without having to copy-paste that assignment for each hardcoded i upto N. This loop does NOT perform some type of iterative operation at runtime.\nSign extension\nRecall the operation where we subtract out the oldest sample and add in the newest. Here’s the code for that:\nacc &lt;= acc\n - {\n     {(AccWidth - DataWidth){sample_buffer[oldest_index][DataWidth-1]}},\n     sample_buffer[oldest_index]\n   }\n + {{(AccWidth - DataWidth){d_in[DataWidth-1]}}, d_in};\nIn short, we’re setting acc &lt;= acc - subtrahend + addend.\nIn the subtrahend, {(AccWidth - DataWidth){sample_buffer[oldest_index][DataWidth-1]}} performs a sign-extension. That’s a bit confusing though since all these values are unsigned. It’s really just a pattern to extend sample_buffer[oldest_index] to the size of the larger acc to allow them to be subtracted. It takes the most significant bit of the oldest sample and replicated it upto the size of acc, then concatenates that with the oldest sample itself.\nSimilarly, {{(AccWidth - DataWidth){d_in[DataWidth-1]}}, d_in} expands d_in to the width of acc.\nThe entire SystemVerilog core\nWith the intuition and notes out of the way, we’ve almost accidentally built the whole circuit. It’s pasted below with comments inline.\nmodule moving_average_accumulator #(\n    // we use Exponent to enforce that k = 2^n\n    parameter integer Exponent  /*verilator public*/  = 3,\n    parameter integer DataWidth  /*verilator public*/ = 16 // n\n) (\n    input wire clk,\n    input wire reset,\n    input wire unsigned [DataWidth-1:0] d_in,\n    output reg unsigned [DataWidth-1:0] d_out\n);\n \n  localparam integer K = 1 &lt;&lt; Exponent;\n  localparam integer AccWidth = DataWidth + Exponent;\n \n  // holds sum of last `N` samples\n  reg unsigned [AccWidth-1:0] acc;\n \n  // circular buffer storing last k samples\n  reg unsigned [DataWidth-1:0] sample_buffer[K];\n \n  // index of oldest element in `sample_buffer`\n  integer oldest_index;\n \n  // loop\n  integer i;\n \n  always_ff @(posedge clk or posedge reset) begin\n    if (reset) begin\n      acc   &lt;= &#039;0;\n      d_out &lt;= &#039;0;\n \n      // reset sample buffer\n      for (i = 0; i &lt; K; i++) begin\n        sample_buffer[i] &lt;= &#039;0;\n      end\n \n      oldest_index &lt;= 0;\n    end else begin\n      // subtract oldest, add newest\n      acc &lt;= acc\n       - {\n           {(AccWidth - DataWidth){sample_buffer[oldest_index][DataWidth-1]}},\n           sample_buffer[oldest_index]\n         }\n       + {{(AccWidth - DataWidth){d_in[DataWidth-1]}}, d_in};\n \n      // overwrite oldest sample\n      sample_buffer[oldest_index] &lt;= d_in;\n \n      // inc oldest_index. wrap around using modulo K\n      oldest_index &lt;= (oldest_index + 1) % K;\n \n      // compute moving average by dividing by 2^exponent\n      d_out &lt;= acc[AccWidth-1:Exponent];  // like a right shift\n    end\n  end\n \nendmodule\nTestbench\nWe have the gateware core completed; now let’s test it. If we can assume some knowledge of C++, I can just explain the testbench in comments:\n// verilator compiles our mov_avg_acc.sv to cpp, that&#039;s the file below\n#include &quot;Vmoving_average_accumulator.h&quot;\n// we&#039;ll instantiate it in our function, run some inputs through it, and compare\n \n#include &quot;verilated.h&quot;\n#include &quot;verilated_vcd_c.h&quot;\n#include &lt;cstdlib&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n \n#define SIM_TIME 20 // Simulation time in clock cycles\n \nint main(int argc, char **argv) {\n  // setup\n  Verilated::commandArgs(argc, argv);\n  // top is a C++ version of the SystemVerilog core we wrote\n  Vmoving_average_accumulator *top = new Vmoving_average_accumulator;\n  VerilatedVcdC *tfp = nullptr;\n  vluint64_t sim_time = 0;\n \n  // these are the input wires we had in out circuit.\n  // we&#039;re setting them up\n  // reset-&gt;1 sets up the sample_buffer\n  top-&gt;clk = 0;\n  top-&gt;reset = 1;\n  top-&gt;d_in = 0;\n \n  // what we&#039;re really doing from here down is setting up the &quot;expected&quot; values\n  // that we&#039;ll compare to the output of our verilog circuit.\n  // to get these expected values, we need to rewrite our circuit&#039;s logic in C++\n \n  // same constants from sv\n  const int Exponent = 3;\n  const int N = 1 &lt;&lt; Exponent;\n  const int DataWidth = 16;\n \n  // our C++ version doesn&#039;t naturally respond to the clock\n  // and hence doesn&#039;t have a delay in its output\n  // we store the values like this to mock this delay\n  uint16_t one_ago = 0;\n  uint16_t two_ago = 0;\n  uint16_t expected_out = 0;\n \n  std::vector&lt;uint16_t&gt; sample_buffer(N, 0);\n  uint32_t acc = 0; // using 32 bits to prevent overflow\n \n  // current index pointing to the oldest sample\n  int oldest_index = 0;\n \n  // simulation loop\n  while (sim_time &lt; SIM_TIME) {\n    // invert clock\n    top-&gt;clk = !top-&gt;clk;\n \n    // allow time for reset\n    if (sim_time &gt; 4)\n      top-&gt;reset = 0;\n \n    // the real logic for the rising edge of the clock\n    if (top-&gt;clk) {\n      // pseudorandom input price\n      uint16_t input_data = (3 * sim_time + 2) % 8031;\n      top-&gt;d_in = input_data; // assert d_in with that price\n \n      // remake the logic in C++\n      if (!top-&gt;reset) {\n        acc -= sample_buffer[oldest_index];\n        acc += input_data;\n        sample_buffer[oldest_index] = input_data;\n \n        oldest_index = (oldest_index + 1) % N;\n \n        // mock the delay\n        two_ago = one_ago;\n        one_ago = expected_out;\n        expected_out = acc &gt;&gt; Exponent;\n \n        // compare and err if bad\n        // if the sim ends without error, we passed\n        if (top-&gt;d_out != two_ago) {\n          std::cerr &lt;&lt; &quot;Mismatch on simtime&quot; &lt;&lt; sim_time &lt;&lt; &quot;: expected &quot;\n                    &lt;&lt; two_ago &lt;&lt; &quot;, got &quot; &lt;&lt; top-&gt;d_out &lt;&lt; std::endl;\n          return EXIT_FAILURE;\n        }\n      }\n    }\n \n    top-&gt;eval();\n \n \n    sim_time++;\n  }\n \n  top-&gt;final();\n \n  // cleanup\n  delete top;\n \n  // test passed\n  std::cout &lt;&lt; &quot;Simulation completed successfully.&quot; &lt;&lt; std::endl;\n  return EXIT_SUCCESS;\n}\nMakefile\nIn order to run this locally and in CI, we’ll use this Makefile:\n# Top-level module name\nTOP_MODULE = moving_average_accumulator\n \n# Verilog source files\nVERILOG_SOURCES = $(TOP_MODULE).sv\n \n# C++ testbench file\nTESTBENCH = tb.cpp\n \n# Output directory\nOBJ_DIR = obj_dir\n \n# Simulation executable\nSIM_EXE = $(OBJ_DIR)/V$(TOP_MODULE)\n \n# Default target\n.PHONY: all\nall: run_simulation\n \n# Compile Verilog and C++ sources\n$(SIM_EXE): $(VERILOG_SOURCES) $(TESTBENCH)\n\tverilator --cc $(VERILOG_SOURCES) --exe $(TESTBENCH) --trace\n\tmake -j -C $(OBJ_DIR) -f V$(TOP_MODULE).mk V$(TOP_MODULE)\n \n# Run the simulation\n.PHONY: run_simulation\nrun_simulation: $(SIM_EXE)\n\t./$(SIM_EXE)\n \n# Clean up generated files\n.PHONY: clean\nclean:\n\trm -rf $(OBJ_DIR) waveform.vcd\n \n# Phony target for CI testing (exits with non-zero status on failure)\n.PHONY: test\ntest: run_simulation\nRunning it\nThat’s all the code. Let’s run it. If you have the dependecies setup, run make test."}}